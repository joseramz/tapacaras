<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Demo cámara + blur de caras</title>
  <style>
    * { box-sizing: border-box; }
    body {
      margin: 0;
      padding: 12px;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      display: flex;
      flex-direction: column;
      gap: 12px;
      background: #f5f5f5;
    }
    h1 { font-size: 18px; margin: 0; }
    .layout { display: flex; flex-wrap: wrap; gap: 12px; }
    #wrap {
      position: relative;
      width: 360px;
      max-width: 100%;
      background: #000;
      border-radius: 8px;
      overflow: hidden;
    }
    video, canvas {
      width: 100%;
      height: auto;
      display: block;
    }
    /* Opcional: ocultar el vídeo si solo quieres ver el canvas procesado */
    video {
      display: none;
    }
    .controls {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      align-items: center;
    }
    button, a.button-link {
      padding: 6px 10px;
      border-radius: 4px;
      border: 1px solid #ccc;
      background: #fff;
      cursor: pointer;
      font-size: 14px;
      text-decoration: none;
      color: #000;
    }
    button:disabled { opacity: 0.5; cursor: default; }
    .note { font-size: 12px; color: #666; }
  </style>
</head>
<body>
  <h1>Demo cámara + blur de caras</h1>
  <p class="note">
    1) Pulsa <strong>Abrir cámara</strong> · 2) Te debería mostrar el vídeo con la cara desenfocada en tiempo real ·
    3) Pulsa <strong>Capturar</strong> para descargar la imagen procesada.
  </p>

  <div class="layout">
    <div id="wrap">
      <video id="video" autoplay playsinline muted></video>
      <canvas id="canvas"></canvas>
    </div>

    <div style="min-width:220px;max-width:300px;">
      <div class="controls">
        <button id="start">Abrir cámara</button>
        <button id="capture" disabled>Capturar</button>
      </div>
      <div class="controls">
        <a id="download" class="button-link" href="javascript:void(0);">Descargar (tras capturar)</a>
      </div>
      <p class="note">
        Todo el procesado (detección + blur) se hace en tu navegador. No se envían imágenes a ningún servidor.
      </p>
    </div>
  </div>

  <!-- MediaPipe Face Detection (global FaceDetection.*) -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const startBtn = document.getElementById('start');
    const captureBtn = document.getElementById('capture');
    const downloadLink = document.getElementById('download');

    let stream = null;
    let faceDetection = null;
    let detectRunning = false;

    // Inicializa MediaPipe Face Detection usando el objeto global "FaceDetection"
    async function initFaceDetection() {
      if (!window.FaceDetection || !FaceDetection.FaceDetection) {
        console.error('FaceDetection no está disponible (fallo al cargar script de MediaPipe).');
        return;
      }

      faceDetection = new FaceDetection.FaceDetection({
        locateFile: (file) =>
          `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`,
      });

      faceDetection.setOptions({
        model: 'short',
        minDetectionConfidence: 0.6,
      });

      faceDetection.onResults(onResults);
    }

    // Dibuja el frame + blur en caras
    function onResults(results) {
      const vw = video.videoWidth;
      const vh = video.videoHeight;
      if (!vw || !vh) return;

      canvas.width = vw;
      canvas.height = vh;

      // Dibujar frame original
      ctx.drawImage(video, 0, 0, vw, vh);

      const detections = (results && results.detections) ? results.detections : [];
      for (const det of detections) {
        const box = det.boundingBox;
        const x = box.xCenter * vw - (box.width * vw) / 2;
        const y = box.yCenter * vh - (box.height * vh) / 2;
        const w = box.width * vw;
        const h = box.height * vh;
        blurRegion(x, y, w, h, 10);
      }
    }

    // Blur sencillo por downscale+upscale en región
    function blurRegion(x, y, w, h, strength = 8) {
      const sx = Math.max(0, Math.floor(x));
      const sy = Math.max(0, Math.floor(y));
      const sw = Math.min(canvas.width - sx, Math.floor(w));
      const sh = Math.min(canvas.height - sy, Math.floor(h));
      if (sw <= 0 || sh <= 0) return;

      const tmp = document.createElement('canvas');
      tmp.width = Math.max(1, Math.floor(sw / strength));
      tmp.height = Math.max(1, Math.floor(sh / strength));
      const tctx = tmp.getContext('2d');

      // downscale
      tctx.drawImage(canvas, sx, sy, sw, sh, 0, 0, tmp.width, tmp.height);
      // upscale (pixelado -> efecto blur)
      ctx.drawImage(tmp, 0, 0, tmp.width, tmp.height, sx, sy, sw, sh);
    }

    // Bucle de detección continuo
    async function detectLoop() {
      if (!detectRunning || !faceDetection) return;

      if (video.readyState >= 2 && video.videoWidth && video.videoHeight) {
        try {
          await faceDetection.send({ image: video });
        } catch (e) {
          console.error('Error en faceDetection.send:', e);
        }
      }

      requestAnimationFrame(detectLoop);
    }

    // Botón abrir cámara
    startBtn.addEventListener('click', async () => {
      try {
        // 1) Cámara (como en la versión mínima que ya sabes que funciona)
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'user' },
          audio: false,
        });
        video.srcObject = stream;
        await video.play();

        // 2) Inicializar face detection (solo la primera vez)
        if (!faceDetection) {
          await initFaceDetection();
        }

        // 3) Arrancar bucle de detección
        detectRunning = true;
        detectLoop();

        captureBtn.disabled = false;
      } catch (err) {
        console.error('Error al acceder a la cámara:', err);
        alert('No se pudo acceder a la cámara. Revisa permisos, HTTPS y ajustes del navegador.');
      }
    });

    // Botón capturar → descarga el frame actual del canvas (ya con blur)
    captureBtn.addEventListener('click', () => {
      if (!canvas.width || !canvas.height) return;

      const data = canvas.toDataURL('image/png');
      downloadLink.href = data;
      downloadLink.download = 'captura-blur.png';
      downloadLink.textContent = 'Descargar captura';
    });

    window.addEventListener('beforeunload', () => {
      if (stream) {
        stream.getTracks().forEach(t => t.stop());
      }
      detectRunning = false;
    });
  </script>
</body>
</html>